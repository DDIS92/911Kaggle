{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import something or python is useless...\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import neighbors\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import Imputer, StandardScaler,MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "\n",
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import LinearSVC, SVC, LinearSVR, SVR\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, BaggingRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import neighbors\n",
    "from sklearn import gaussian_process\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn import neural_network\n",
    "\n",
    "from sklearn import grid_search\n",
    "from sklearn import feature_extraction, feature_selection\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SelectOneColumn(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # return X.ix[:, self.column]\n",
    "        return X[self.column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DictVectSeries(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):   \n",
    "        if ((type(X[X.index[0]]) is str) | (type(X[X.index[0]]) is unicode)) == False:\n",
    "            X = X.astype(str)       \n",
    "        samples = [dict(enumerate(sample)) for sample in X]        \n",
    "        self.dict_ = DictVectorizer()      \n",
    "        self.dict_.fit(samples)       \n",
    "        return self\n",
    "\n",
    "    \n",
    "    def transform(self, X, y=None):      \n",
    "        if ((type(X[X.index[0]]) is str) | (type(X[X.index[0]]) is unicode)) == False:\n",
    "            X = X.astype(str)   \n",
    "        samples = [dict(enumerate(sample)) for sample in X]      \n",
    "        return self.dict_.transform(samples)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DenseTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.todense()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DFback(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self = self\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # return X.ix[:, self.column]\n",
    "        return pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SeriesImputer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" Impute missing values.\n",
    "       Columns of dtype object are imputed with the most frequent value \n",
    "       in column.\n",
    "\n",
    "       Columns of other types are imputed with mean of column.\n",
    "    \"\"\"\n",
    "       # def __init__(self)\n",
    "   \n",
    "    def fit(self, X, y=None):\n",
    "        if len(X.mode()) != 0 :\n",
    "            self.fill = (X.mode()[0] if ((X.dtype == np.dtype('O')) | (X.dtype == np.dtype(tuple)))  else X.mean())\n",
    "        else :      \n",
    "            self.fill = X[X.first_valid_index()]        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GetVectorizeTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self = self\n",
    "        \n",
    "    def fit(self, X, *_):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, *_):\n",
    "       # if isinstance(X, pd.Series):\n",
    "        return feature_extraction.text.TfidfVectorizer().fit_transform(X)\n",
    "       # else:\n",
    "     #       raise TypeError(\"This transformer only works with Pandas Dataframes\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the training file to see what mess we have...\n",
    "df = pd.read_csv('fullzip')\n",
    "df = df.drop(\"Unnamed: 0\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at the headers...\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert date time to date time\n",
    "df.timeStamp = pd.to_datetime(df.timeStamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check the data types and see where our blank fields are...\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# so no need to reload again in case messed up\n",
    "df_original = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make time stamp the index\n",
    "df.set_index('timeStamp', inplace=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()\n",
    "#seems all are categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#guys this is for checking how many unique fields for each column, maybe useful for you guys in future\n",
    "[(c, df[c].value_counts().count()) for c in list(df.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#maybe we should treat 'lat' and 'lng' as a pair rather than view separately?\n",
    "df['coordinate'] = zip(df['lat'],df['lng'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df['coordinate'].unique())\n",
    "#great, it's pretty much the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.groupby('coordinate').count().sort_values('emergencytype',ascending=False).head()\n",
    "#this may tell us something\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df['coordinate'] == (40.0972222, -75.3761952)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe_list_dummies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe_list_dummies.append( ('coordinate', make_pipeline(SelectOneColumn('coordinate'),DictVectSeries(),DenseTransformer())) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe_list_dummies.append( ('zip', make_pipeline(SelectOneColumn('zip'),SeriesImputer(),DictVectSeries(),DenseTransformer())) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe_list_dummies.append( ('twp', make_pipeline(SelectOneColumn('twp'),SeriesImputer(),DictVectSeries(),DenseTransformer())) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pipe_list_dummies.append( ('desc', make_pipeline(SelectOneColumn('desc'),SeriesImputer(),TfidfVectorizer(),DenseTransformer())) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe_list_dummies.append( ('addr', make_pipeline(SelectOneColumn('addr'),SeriesImputer(),TfidfVectorizer(),DenseTransformer())) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#coordinate_pipe = Pipeline([('Col_coordinate', SelectOneColumn('coordinate')), \n",
    "                      #('Fill_na_coordinate', SeriesImputer()),\n",
    "                      #                      ('Dummy_coordinate', DictVectSeries())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df.coordinate.mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "union = FeatureUnion(pipe_list_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "union_model_pipe = Pipeline([('union', union),                     \n",
    "                    ('Model', RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = cross_validation.KFold(len(df), n_folds=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = cross_validation.cross_val_score(union_model_pipe, df, df['emergencytype'], cv=cv, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lazy mode\n",
    "\n",
    "# What happens if we drop na?\n",
    "data = df.dropna()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 67626 non-blank record seems not bad la...\n",
    "\n",
    "# continue lazy mode!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "list(data.columns)\n",
    "\n",
    "\n",
    "col = ['id', # key\n",
    "       'lat', # location\n",
    "       'lng', # location\n",
    "       'desc', # free text\n",
    "       'zip', # location\n",
    "       'twp', # location\n",
    "       'addr', # location\n",
    "       'e', # unknown data?\n",
    "       'emergencytype', # categorical\n",
    "       'emergencysubtype' # categorical\n",
    "       ]\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at categorical data\n",
    "cat_cols = ['e', # unknown data?\n",
    "            'emergencytype', # categorical\n",
    "            'emergencysubtype' # categorical\n",
    "           ]\n",
    "for col in cat_cols:\n",
    "    print col, ':', len(data[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sleep"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
